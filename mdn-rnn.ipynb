{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, InputLayer, Attention\n",
    "from tensorflow.keras.layers import (Conv2D, Input, Reshape, \n",
    "                                     Lambda, Dense, Conv2DTranspose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import utils\n",
    "from utils import sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(LATENT_SIZE=32):\n",
    "    inputs = Input(shape=(64, 64, 3), name='encoder_input')\n",
    "    h = Conv2D(32, 4, strides=2, activation=\"relu\", name=\"enc_conv1\")(inputs)\n",
    "    h = Conv2D(64, 4, strides=2, activation=\"relu\", name=\"enc_conv2\")(h)\n",
    "    h = Conv2D(128, 4, strides=2, activation=\"relu\", name=\"enc_conv3\")(h)\n",
    "    h = Conv2D(256, 4, strides=2, activation=\"relu\", name=\"enc_conv4\")(h)\n",
    "    h = Reshape([2*2*256])(h)\n",
    "    z_mean = Dense(LATENT_SIZE, name='z_mean')(h)\n",
    "    z_log_var = Dense(LATENT_SIZE, name='z_log_var')(h)\n",
    "    z = Lambda(sampling, output_shape=(LATENT_SIZE,), name='z')([z_mean, z_log_var])\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "act_len = 3\n",
    "n_mixtures = 5\n",
    "output_dims = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_dir = './data/traces'\n",
    "traces = os.listdir(trace_dir)\n",
    "trace = np.load(os.path.join(trace_dir, traces[0]))\n",
    "ims = trace['b']\n",
    "ims = utils.preprocess_images(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Encoder()\n",
    "e.load_weights('./data/weights/encoder_weights.h5')\n",
    "z = utils.to_latent(e, ims)\n",
    "actions = trace['a']\n",
    "pair = np.concatenate((z, actions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dataset = tf.data.Dataset.from_tensor_slices(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = latent_dataset.batch(seq_len + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (129, 35), types: tf.float64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_z = chunk[:-1]\n",
    "    target_z = chunk[1:, :32]\n",
    "    return input_z, target_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((128, 35), (128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(utils.BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 128, 35), (128, 128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a, b in dataset:\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_20 = i // 5\n",
    "val = dataset.take(percent_20)\n",
    "train = dataset.skip(percent_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((128, 128, 35), (128, 128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset shapes: ((128, 128, 35), (128, 128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN_RNN(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 latent_size=32, \n",
    "                 seq_length=128,\n",
    "                 act_len=3,\n",
    "                 output_dims=1,\n",
    "                 n_mixtures=5,\n",
    "                 hlayer=LSTM,\n",
    "                 hidden_size=256, \n",
    "                 optimizer='adam',):\n",
    "        \n",
    "        \"\"\"Initializer for MDN-RNN\"\"\"\n",
    "        \n",
    "        super(MDN_RNN, self).__init__()\n",
    "        self.latent_dim  = latent_size\n",
    "        self.seq_len     = seq_length\n",
    "        self.act_len     = act_len\n",
    "        self.output_dims = output_dims\n",
    "        self.n_mixtures  = n_mixtures\n",
    "        self.hlayer      = hlayer\n",
    "        self.h_size      = hidden_size\n",
    "        self.optim       = optimizer\n",
    "        self.T           = 1.25\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------#\n",
    "    #            LAYER DEFINITIONS            #\n",
    "    # ----------------------------------------#\n",
    "    \n",
    "        self.input_ = InputLayer(\n",
    "                        batch_size = None,\n",
    "                        input_shape = (self.seq_len, \n",
    "                                       self.act_len + utils.LATENT_SIZE),\n",
    "                        name='m_input'\n",
    "                    )\n",
    "        \n",
    "        self.rnn =   self.hlayer(self.h_size, return_state=True, \n",
    "                                             name='encoder')\n",
    "        \n",
    "        self.z_pi    =  Dense(self.n_mixtures * self.output_dims)\n",
    "        self.z_mu    =  Dense(self.n_mixtures * self.output_dims)\n",
    "        self.z_sigma =  Dense(self.n_mixtures * self.output_dims)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.input_(inputs)\n",
    "        r_output, state_h, state_c = self.rnn(x)\n",
    "        \n",
    "        pi = self.z_pi(r_output)\n",
    "        print(pi.shape)\n",
    "        pi = tf.reshape(pi, shape=(-1, \n",
    "                                   self.seq_len, \n",
    "                                   self.n_mixtures, \n",
    "                                   self.latent_dim))\n",
    "        pi = tf.math.softmax(pi, axis=2)\n",
    "        pi = pi / self.T\n",
    "        \n",
    "        \n",
    "        sigma = tf.math.exp(self.z_sigma(r_output))\n",
    "        sigma = tf.reshape(sigma, shape=(-1, \n",
    "                                           self.seq_len, \n",
    "                                           self.n_mixtures, \n",
    "                                           self.latent_dim))\n",
    "        sigma = sigma * self.T**0.5\n",
    "        \n",
    "        mu = self.z_mu(r_output)\n",
    "        mu = tf.reshape(mu, shape=(-1, \n",
    "                                   self.seq_len, \n",
    "                                   self.n_mixtures, \n",
    "                                   self.latent_dim))\n",
    "        # reshape to (-1, seqlen, n_mixtures, latent)\n",
    "\n",
    "        return pi, sigma, mu           \n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(tf.keras.Model, self).get_config()\n",
    "        config.update({'latent_size': self.latent_dim, \n",
    "                       'seq_len':     self.seq_len,\n",
    "                       'act_len':     self.act_len,\n",
    "                       'output_dims': self.output_dims,\n",
    "                       'n_mixtures':  self.n_mixtures,\n",
    "                       'hlayer':      self.hlayer,\n",
    "                       'h_size':      self.h_size,\n",
    "                       'optim':       self.optim})\n",
    "        return config\n",
    "        \n",
    "        \n",
    "\n",
    "def mdn_loss_func(y_true, y_pred):\n",
    "        # Reshape inputs in case this is used in a TimeDistribued layer\n",
    "        y_pred = tf.reshape(y_pred, [-1, (2 * n_mixtures * output_dims) + n_mixtures], name='reshape_ypreds')\n",
    "        y_true = tf.reshape(y_true, [-1, output_dims], name='reshape_ytrue')\n",
    "        # Split the inputs into paramaters\n",
    "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[n_mixtures * output_dims,\n",
    "                                                                         n_mixtures * output_dims,\n",
    "                                                                         n_mixtures],\n",
    "                                             axis=-1, name='mdn_coef_split')\n",
    "        # Construct the mixture models\n",
    "        cat = tfd.Categorical(logits=out_pi)\n",
    "        component_splits = [output_dims] * n_mixtures\n",
    "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
    "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
    "        coll = [tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
    "                in zip(mus, sigs)]\n",
    "        mixture = tfd.Mixture(cat=cat, components=coll)\n",
    "        loss = mixture.log_prob(y_true)\n",
    "        loss = tf.negative(loss)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return loss\n",
    "\n",
    "M = MDN_RNN() # DOES NOT WORK. \n",
    "# M.compile(optimizer=M.optim, loss=mdn_loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "act_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIMS = 1\n",
    "N_MIXES     = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Sequential([\n",
    "    Input((seq_len, act_len + utils.LATENT_SIZE)),\n",
    "    LSTM(256),\n",
    "    mdn.MDN(OUTPUT_DIMS, N_MIXES)\n",
    "])\n",
    "\n",
    "M.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMS, N_MIXES), \n",
    "          optimizer=tf.keras.optimizers.Adam()\n",
    "         )\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sausage2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_dir = './data/traces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = os.listdir(trace_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = np.load(os.path.join(trace_dir, traces[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 128\n",
    "# LATENT_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = trace['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = utils.preprocess_images(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sausage_to_seq(sausage, seq_len):\n",
    "    return np.array(np.split(sausage, sausage.shape[0] / seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = sausage_to_seq(z, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_ = np.array(np.split(y_true, z.shape[0] / utils.BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([y_true, y_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = sausage_to_seq(pair, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = np.array([pair, pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    M.fit(pair, y_true, batch_size=utils.BATCH_SIZE, epochs=5)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
