{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, InputLayer, Attention\n",
    "from tensorflow.keras.layers import (Conv2D, Input, Reshape, \n",
    "                                     Lambda, Dense, Conv2DTranspose)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import utils\n",
    "\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint, \n",
    "                                       TensorBoard, Callback)\n",
    "import datetime\n",
    "from time import time\n",
    "from utils import TrainTimeCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "act_len = 3\n",
    "n_mixtures = 5\n",
    "output_dims = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          16020        1703        7044           3        7273       13946\r\n",
      "Swap:          4095          43        4051\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = len(os.listdir('./data/states'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(path):\n",
    "    files = os.listdir(path)\n",
    "    _1 = np.load(os.path.join(path, files[0]))\n",
    "    data = np.zeros((len(files), *_1.shape))\n",
    "    for i, fname in enumerate(files):\n",
    "        data[i] = np.load(os.path.join(path, fname))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_states = load_folder('./data/z_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154624, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = load_folder('./data/actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154624, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.4375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "154624 / 128 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = np.concatenate((z_states, actions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154624, 35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dataset = tf.data.Dataset.from_tensor_slices(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = latent_dataset.batch(seq_len + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (129, 35), types: tf.float64>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_z = chunk[:-1]\n",
    "    target_z = chunk[1:, :32]\n",
    "    return input_z, target_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((128, 35), (128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(utils.BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 128, 35), (128, 128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a, b in dataset:\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_20 = i // 5\n",
    "val = dataset.take(percent_20)\n",
    "train = dataset.skip(percent_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((128, 128, 35), (128, 128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset shapes: ((128, 128, 35), (128, 128, 32)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./logs/’: File exists\n",
      "mkdir: cannot create directory ‘./logs/fit’: File exists\n",
      "rm: cannot remove './logs/fit/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"./logs/\"\n",
    "!mkdir \"./logs/fit\"\n",
    "!rm \"./logs/fit/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "act_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    TrainTimeCallback(),\n",
    "    ModelCheckpoint('./best_mdn_rnn.h5', save_best_only=True, \n",
    "                    monitor='val_loss', save_weights_only=True),\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128, 256)          299008    \n",
      "_________________________________________________________________\n",
      "mdn (MDN)                    (None, 128, 325)          83525     \n",
      "=================================================================\n",
      "Total params: 382,533\n",
      "Trainable params: 382,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_dims = 32\n",
    "n_mixes     = 5\n",
    "M = Sequential([\n",
    "    Input((seq_len, act_len + utils.LATENT_SIZE)),\n",
    "    LSTM(256, return_sequences=True),\n",
    "    mdn.MDN(output_dims, n_mixes)\n",
    "])\n",
    "\n",
    "M.compile(loss=mdn.get_mixture_loss_func(output_dims, n_mixes), \n",
    "          optimizer=tf.keras.optimizers.Adam(), \n",
    "          callbacks=callbacks,\n",
    "         )\n",
    "\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 372ms/step - loss: 38.5307 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 33.1567 - val_loss: 30.0616\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 28.7403 - val_loss: 26.8452\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 26.0379 - val_loss: 23.8789\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 23.8192 - val_loss: 23.7365\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 22.7239 - val_loss: 21.4102\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 21.9298 - val_loss: 21.5287\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 20.8378 - val_loss: 20.9831\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 20.8103 - val_loss: 19.6289\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 20.5868 - val_loss: 19.7909\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 19.7254 - val_loss: 19.3182\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 19.2568 - val_loss: 24.5437\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 21.3469 - val_loss: 19.1314\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 19.3756 - val_loss: 19.8110\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 19.5464 - val_loss: 19.3018\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 18.7708 - val_loss: 18.7637\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 18.8209 - val_loss: 18.2053\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 18.3915 - val_loss: 18.7074\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 18.0984 - val_loss: 17.6844\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.1096 - val_loss: 19.1820\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 18.5212 - val_loss: 18.0245\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 18.1165 - val_loss: 17.8995\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 21.2778 - val_loss: 24.0933\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 23.8891 - val_loss: 23.7758\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 23.6051 - val_loss: 23.3077\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 23.2867 - val_loss: 23.0370\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 22.8539 - val_loss: 22.6122\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 22.6144 - val_loss: 23.2656\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 21.9838 - val_loss: 20.6087\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 20.7322 - val_loss: 20.5515\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 21.2482 - val_loss: 20.4650\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 20.0450 - val_loss: 19.4234\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 20.0113 - val_loss: 20.9346\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 20.4679 - val_loss: 21.6085\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 20.3881 - val_loss: 19.6849\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 19.9626 - val_loss: 19.7147\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 18.5979 - val_loss: 17.1170\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 16.6502 - val_loss: 16.4045\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 16.2400 - val_loss: 15.7073\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.5459 - val_loss: 15.5555\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 17.3500 - val_loss: 16.2360\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 15.7570 - val_loss: 15.7334\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 16.1730 - val_loss: 15.2940\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.2647 - val_loss: 15.0719\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 15.2672 - val_loss: 15.1169\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 16.8628 - val_loss: 15.7059\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.4181 - val_loss: 15.2712\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 15.1913 - val_loss: 14.9811\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 15.0834 - val_loss: 23.7627\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 22.1369 - val_loss: 21.0581\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 21.0562 - val_loss: 20.6229\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 20.8302 - val_loss: 20.6887\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 20.7960 - val_loss: 20.3301\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 20.2263 - val_loss: 19.9051\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.4243 - val_loss: 19.8373\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 20.0109 - val_loss: 19.3076\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 19.4127 - val_loss: 19.4210\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 19.2221 - val_loss: 18.9789\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.1924 - val_loss: 20.6861\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.9474 - val_loss: 19.3120\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.1832 - val_loss: 18.8419\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 18.9982 - val_loss: 19.1082\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.7522 - val_loss: 19.1049\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 19.0371 - val_loss: 18.7682\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.1247 - val_loss: 19.1505\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 18.9847 - val_loss: 18.5443\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 18.6644 - val_loss: 18.6446\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 19.3208 - val_loss: 19.4033\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 17.6631 - val_loss: 15.7940\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 15.9536 - val_loss: 15.0416\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 15.6891 - val_loss: 15.3736\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 15.4756 - val_loss: 15.2839\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.0633 - val_loss: 14.8138\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.0808 - val_loss: 15.6413\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.3749 - val_loss: 14.8404\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 14.7253 - val_loss: 14.4324\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.0461 - val_loss: 15.3339\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 15.0130 - val_loss: 14.3552\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 14.3046 - val_loss: 14.3020\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 14.1201 - val_loss: 14.2019\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 15.1880 - val_loss: 15.3523\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 56ms/step - loss: 15.2063 - val_loss: 14.2729\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 14.4362 - val_loss: 14.1446\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 14.1464 - val_loss: 14.7200\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 14.6522 - val_loss: 14.2643\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 14.2669 - val_loss: 13.7082\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 13.9680 - val_loss: 14.0284\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 14.1267 - val_loss: 15.0762\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 14.4318 - val_loss: 13.9782\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 13.8827 - val_loss: 13.6977\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 13.7656 - val_loss: 13.7779\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 13.7192 - val_loss: 13.4508\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 14.1715 - val_loss: 16.6676\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 15.1289 - val_loss: 14.3697\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 14.0139 - val_loss: 13.6884\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 13.9387 - val_loss: 15.9511\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 14.5001 - val_loss: 13.9590\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 14.0557 - val_loss: 13.5503\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 13.7659 - val_loss: 13.7630\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 13.6359 - val_loss: 13.6546\n"
     ]
    }
   ],
   "source": [
    "history = M.fit(train, epochs=100, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
